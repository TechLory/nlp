{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Markov N-gram language model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"/Users/flint/Data/wordlists/generated/gpt-5000.json\"\n",
    "with open(data, 'r') as infile:\n",
    "    docs = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am Norman and today I involve all the members of the Society together, and to whom I express my deepest gratitude, and hope in the future.\n",
      "I am Gene and today I have your name written in the corner  The man I am with is a former convict. You are our friend.\n",
      "I am Alice and today I feel free. It will not be too hard to make something you can call a life or a career.\n",
      "I am Daniel and today I be announcing to you that I am a true gentleman, an Atheist!\"  His mother did not respond.\n"
     ]
    }
   ],
   "source": [
    "corpus = docs['corpus']\n",
    "np.random.shuffle(corpus)\n",
    "for document in corpus[:4]:\n",
    "    print(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    return ['#S'] + word_tokenize(text.lower()) + ['#E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [tokenizer(doc) for doc in corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marlov Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import nltk \n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkovModel:\n",
    "    def __init__(self, k: int = 2, alpha: float = 0.0001):\n",
    "        self.k = k\n",
    "        self.alpha = alpha\n",
    "        self.index = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "    def read(self, doc: list[str]):\n",
    "        for k_gram in nltk.ngrams(doc, n=self.k, pad_left=True, pad_right=True, left_pad_symbol='[PAD]', right_pad_symbol='[PAD]'):\n",
    "            prefix, suffix = k_gram[:-1], k_gram[-1]\n",
    "            self.index[prefix][suffix] += 1\n",
    "    def read_multi(self, docs: list):\n",
    "        for doc in tqdm(docs):\n",
    "            self.read(doc)\n",
    "    def p(self, w: str, prefix: tuple):\n",
    "        n = self.index[prefix][w]\n",
    "        d = sum(self.index[prefix].values())\n",
    "        if n == 0 or d == 0:\n",
    "            return self.alpha\n",
    "        else:\n",
    "            return n / d\n",
    "    def eval_prob(self, doc: list):\n",
    "        probs = []\n",
    "        for k_gram in nltk.ngrams(doc, n=self.k, pad_left=True, pad_right=True, left_pad_symbol='[PAD]', right_pad_symbol='[PAD]'):\n",
    "            p = self.p(k_gram[-1], prefix=k_gram[:-1])\n",
    "            probs.append(np.log(p))\n",
    "        return sum(probs)\n",
    "        \n",
    "    def generate(self, prefix: tuple = None, max_len: int = 1000):\n",
    "        if prefix is None:\n",
    "            prefix = tuple(['[PAD]']*(self.k-2) + ['#S'])\n",
    "        document = [x for x in prefix]\n",
    "        for i in range(max_len):\n",
    "            candidates, probabilities = [], []\n",
    "            for w in self.index[prefix].keys():\n",
    "                p = self.p(w, prefix)\n",
    "                candidates.append(w)\n",
    "                probabilities.append(p)\n",
    "            new_word = np.random.choice(candidates, p=probabilities)\n",
    "            document.append(new_word)\n",
    "            prefix = tuple(document[-(self.k - 1):])\n",
    "            if new_word == '#E':\n",
    "                break \n",
    "        return document\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MarkovModel(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbf558c128e141549ef4595b49131afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4043 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.read_multi(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PAD] #S i am david and today i have a choice . #E\n"
     ]
    }
   ],
   "source": [
    "doc = model.generate(max_len=100)\n",
    "print(\" \".join(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am david and today i have a choice . -12.445900365412808\n",
      "the cat is on the table . -73.68272297580945\n",
      "i am william and i work on the table . -53.17286928272703\n"
     ]
    }
   ],
   "source": [
    "s = [\"i am david and today i have a choice .\", \"the cat is on the table .\", \"i am william and i work on the table .\"]\n",
    "for x in s:\n",
    "    tokens = tokenizer(x)\n",
    "    print(x, model.eval_prob(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
