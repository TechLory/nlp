{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp.data import load_20news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_20news()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "I am sure some bashers of Pens fans are pretty confused about the lack\n",
      "of any kind of posts about the recent Pens massacre of the Devils. Actually,\n",
      "I am  bit puzzled too and a bit relieved. However, I am going to put an end\n",
      "to non-PIttsburghers' relief with a bit of praise for the Pens. Man, they\n",
      "are killing those Devils worse than I thought. Jagr just showed you why\n",
      "he is much better than his regular season stats. He is also a lot\n",
      "fo fun to watch in the playoffs. Bowman should let JAgr have a \n",
      "...\n",
      "10 rec.sport.hockey\n"
     ]
    }
   ],
   "source": [
    "print(data.data[0][:500], '\\n...')\n",
    "print(data.target[0], data.target_names[data.target[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import regexp_tokenize, wordpunct_tokenize, blankline_tokenize, word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp.data import frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizers = {\n",
    "    'nltk': lambda text: word_tokenize(text),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {}\n",
    "for model, tokenizer in tokenizers.items():\n",
    "    output[model] = frequency(data.data, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = output['nltk'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217350"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ",      178323\n",
       ".      167364\n",
       "the    154712\n",
       ">       90224\n",
       "--      88285\n",
       "to      84950\n",
       "of      75632\n",
       "a       66300\n",
       "and     65816\n",
       "'AX     61725\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_tokenizer(text, n = 2):\n",
    "    unigrams = word_tokenize(text)\n",
    "    return list(nltk.ngrams(unigrams, n=n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bfreq = frequency(data.data, tokenizer=n_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "York ,          with freq 131\n",
      "York Times      with freq 36\n",
      "York City       with freq 32\n",
      "York University with freq 20\n",
      "York Rangers    with freq 18\n",
      "York (          with freq 17\n",
      "York Islanders  with freq 17\n",
      "York .          with freq 16\n",
      "York Mets       with freq 15\n",
      "York Yankees    with freq 15\n",
      "York and        with freq 9\n",
      "York )          with freq 9\n",
      "York :          with freq 8\n",
      "York in         with freq 7\n",
      "York ?          with freq 7\n",
      "York &          with freq 5\n",
      "York State      with freq 5\n",
      "York at         with freq 3\n",
      "York Times_     with freq 3\n",
      "York _Times_    with freq 3\n",
      "York [          with freq 3\n",
      "York 13676      with freq 2\n",
      "York to         with freq 2\n",
      "York 's         with freq 2\n",
      "York law        with freq 2\n",
      "York Daily      with freq 2\n",
      "York 6          with freq 2\n",
      "York ADL        with freq 2\n",
      "York H.         with freq 2\n",
      "York 14215      with freq 2\n",
      "York Court      with freq 2\n",
      "York will       with freq 2\n",
      "York office     with freq 2\n",
      "York Academy    with freq 2\n",
      "York is         with freq 2\n",
      "York Philharmonic with freq 2\n",
      "York 4          with freq 2\n",
      "York d.         with freq 2\n",
      "York gave       with freq 1\n",
      "York Area       with freq 1\n",
      "York 1955       with freq 1\n",
      "York 1946       with freq 1\n",
      "York are        with freq 1\n",
      "York a          with freq 1\n",
      "York ever       with freq 1\n",
      "York teams      with freq 1\n",
      "York Date       with freq 1\n",
      "York NYC-Aquaduct with freq 1\n",
      "York 10257      with freq 1\n",
      "York area       with freq 1\n",
      "York -          with freq 1\n",
      "York talk       with freq 1\n",
      "York Geneva     with freq 1\n",
      "York resident   with freq 1\n",
      "York Toronto    with freq 1\n",
      "York mission    with freq 1\n",
      "York headquarters with freq 1\n",
      "York feel       with freq 1\n",
      "York city       with freq 1\n",
      "York 3          with freq 1\n",
      "York 9          with freq 1\n",
      "York NY         with freq 1\n",
      "York where      with freq 1\n",
      "York publishing with freq 1\n",
      "York azure.acsu.buffalo.edu with freq 1\n",
      "York Hear       with freq 1\n",
      "York call       with freq 1\n",
      "York also       with freq 1\n",
      "York state      with freq 1\n",
      "York but        with freq 1\n",
      "York with       with freq 1\n",
      "York came       with freq 1\n",
      "York state-owned with freq 1\n",
      "York Trade      with freq 1\n",
      "York 0          with freq 1\n",
      "York Year       with freq 1\n",
      "York Gave       with freq 1\n",
      "York Football   with freq 1\n",
      "York Titans     with freq 1\n",
      "York prohibits  with freq 1\n",
      "York Bunch      with freq 1\n",
      "York Steinbrenners with freq 1\n",
      "York 10461      with freq 1\n",
      "York 14642      with freq 1\n",
      "York 10016-9103 with freq 1\n",
      "York 10032      with freq 1\n",
      "York 14263      with freq 1\n",
      "York Avenue     with freq 1\n",
      "York 10021      with freq 1\n",
      "York that       with freq 1\n",
      "York 68         with freq 1\n",
      "York 48         with freq 1\n",
      "York Telephone  with freq 1\n",
      "York One's      with freq 1\n",
      "York !          with freq 1\n",
      "York TImes      with freq 1\n",
      "York 2          with freq 1\n",
      "York 1:05pm     with freq 1\n",
      "York 7:35pm     with freq 1\n",
      "York newspapers with freq 1\n",
      "York news       with freq 1\n"
     ]
    }
   ],
   "source": [
    "for (a, b), c in bfreq.sort_values(ascending=False).items():\n",
    "    if a == 'York':\n",
    "        print(f\"{a} {b:10} with freq {c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "--              --                75547\n",
       ">               'AX               61403\n",
       "'AX             >                 61336\n",
       "of              the               18416\n",
       "*               *                 17977\n",
       "                                  ...  \n",
       "arm             as                    1\n",
       "he              wrapped-around        1\n",
       "wrapped-around  the                   1\n",
       "searching       out                   1\n",
       "else            shed                  1\n",
       "Length: 1316849, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bfreq.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = freq.sum()\n",
    "M = bfreq.sum()\n",
    "\n",
    "def p_u(word):\n",
    "    return freq[word] / N\n",
    "\n",
    "def p_b(w_i, w_j):\n",
    "    return bfreq[(w_i, w_j)] / M\n",
    "\n",
    "def mu(w_i, w_j):\n",
    "    return np.log(p_b(w_i, w_j) / ( p_u(w_i) * p_u(w_j) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "MU = pd.Series(dict([((a, b), mu(a, b)) for (a, b), c in bfreq.items() if c > 100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Serdar      Argic             10.271776\n",
       "Newsletter  Page              10.178196\n",
       "HICNet      Medical           10.048172\n",
       "Medical     Newsletter         9.913515\n",
       "Los         Angeles            9.843628\n",
       "MS.         MYERS              9.667125\n",
       "St.         Louis              9.370098\n",
       "Holy        Spirit             9.360028\n",
       "Attorney    General            9.274592\n",
       "MR.         STEPHANOPOULOS     9.267149\n",
       "San         Francisco          9.256040\n",
       "Second      Amendment          9.176258\n",
       "White       House              9.149028\n",
       "_/          _/                 9.134090\n",
       "Clipper     Chip               9.129130\n",
       "San         Jose               9.036434\n",
       "United      States             8.967750\n",
       "greatly     appreciated        8.456415\n",
       "THE         PRESIDENT          8.322351\n",
       "New         York               8.277016\n",
       "dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MU.sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
