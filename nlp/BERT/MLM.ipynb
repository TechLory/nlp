{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [\"If i have seen further it is by standing on the shoulders of giants\", \n",
    "         \"\"\"You take the blue pill, the story ends, you wake up in your bed and believe whatever you want to believe. \n",
    "          You take the red pill, you stay in wonderland, and I show you how deep the rabbit hole goes.\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "\n",
    "model_checkpoint = 'bert-base-uncased'\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_checkpoint)\n",
    "model = BertForMaskedLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(sents[1], return_tensors='pt')\n",
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2017,  2202,  1996,  2630, 17357,  1010,  1996,  2466,  4515,\n",
       "          1010,  2017,  5256,  2039,  1999,  2115,  2793,  1998,  2903,  3649,\n",
       "          2017,  2215,  2000,  2903,  1012,  2017,  2202,  1996,  2417, 17357,\n",
       "          1010,  2017,  2994,  1999, 20365,  1010,  1998,  1045,  2265,  2017,\n",
       "          2129,  2784,  1996, 10442,  4920,  3632,  1012,   102]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'you',\n",
       " 'take',\n",
       " 'the',\n",
       " 'blue',\n",
       " 'pill',\n",
       " ',',\n",
       " 'the',\n",
       " 'story',\n",
       " 'ends',\n",
       " ',',\n",
       " 'you',\n",
       " 'wake',\n",
       " 'up',\n",
       " 'in',\n",
       " 'your',\n",
       " 'bed',\n",
       " 'and',\n",
       " 'believe',\n",
       " 'whatever',\n",
       " 'you',\n",
       " 'want',\n",
       " 'to',\n",
       " 'believe',\n",
       " '.',\n",
       " 'you',\n",
       " 'take',\n",
       " 'the',\n",
       " 'red',\n",
       " 'pill',\n",
       " ',',\n",
       " 'you',\n",
       " 'stay',\n",
       " 'in',\n",
       " 'wonderland',\n",
       " ',',\n",
       " 'and',\n",
       " 'i',\n",
       " 'show',\n",
       " 'you',\n",
       " 'how',\n",
       " 'deep',\n",
       " 'the',\n",
       " 'rabbit',\n",
       " 'hole',\n",
       " 'goes',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(inputs.input_ids.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['labels'] = inputs.input_ids.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 48])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "rand = torch.rand(inputs.input_ids.shape)\n",
    "rand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7205, 0.1658, 0.1057, 0.0520, 0.7546, 0.3930, 0.3884, 0.8775, 0.8032,\n",
       "         0.2962, 0.0760, 0.9871, 0.7788, 0.0054, 0.1518, 0.1919, 0.0753, 0.6940,\n",
       "         0.4691, 0.6437, 0.3575, 0.7355, 0.2558, 0.9634, 0.2008, 0.8292, 0.2374,\n",
       "         0.2651, 0.5348, 0.4916, 0.7210, 0.7809, 0.0460, 0.8596, 0.0934, 0.6334,\n",
       "         0.3133, 0.2361, 0.1499, 0.2465, 0.3866, 0.1169, 0.7835, 0.5023, 0.6070,\n",
       "         0.8289, 0.1491, 0.5446]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False,  True,  True, False, False, False, False, False, False,\n",
       "          True, False, False,  True, False, False,  True, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False,  True, False,  True, False, False, False,  True, False,\n",
       "         False,  True, False, False, False, False,  True, False]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_arr = rand < 0.15\n",
    "mask_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 102)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.cls_token_id, tokenizer.sep_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True, False]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(inputs.input_ids != 101) * (inputs.input_ids != 102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * (inputs.input_ids != 102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2],\n",
       "        [ 3],\n",
       "        [10],\n",
       "        [13],\n",
       "        [16],\n",
       "        [32],\n",
       "        [34],\n",
       "        [38],\n",
       "        [41],\n",
       "        [46]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_arr.squeeze().nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 10, 13, 16, 32, 34, 38, 41, 46]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten(mask_arr.squeeze().nonzero()).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = torch.flatten(mask_arr.squeeze().nonzero()).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2017,   103,   103,  2630, 17357,  1010,  1996,  2466,  4515,\n",
       "           103,  2017,  5256,   103,  1999,  2115,   103,  1998,  2903,  3649,\n",
       "          2017,  2215,  2000,  2903,  1012,  2017,  2202,  1996,  2417, 17357,\n",
       "          1010,  2017,   103,  1999,   103,  1010,  1998,  1045,   103,  2017,\n",
       "          2129,   103,  1996, 10442,  4920,  3632,   103,   102]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids[0, selection] = tokenizer.mask_token_id\n",
    "inputs.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['loss', 'logits'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(**inputs)\n",
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0346, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([48, 30522])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.logits\n",
    "output.logits.shape\n",
    "output.logits.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -6.6016,  -6.6369,  -6.5849,  ...,  -6.5788,  -5.4299,  -8.8540],\n",
       "        [ -9.5204,  -9.6540,  -9.5063,  ...,  -8.6586,  -7.2781,  -9.8042],\n",
       "        [-10.0009,  -9.9783,  -9.9150,  ...,  -8.6355,  -8.4966,  -6.1108],\n",
       "        ...,\n",
       "        [ -4.5535,  -4.7403,  -4.3238,  ...,  -4.1134,  -4.2732,  -5.1083],\n",
       "        [ -7.9456,  -7.9177,  -7.8825,  ...,  -7.4334,  -7.8555,  -6.3171],\n",
       "        [ -9.1215,  -9.0175,  -9.1682,  ...,  -8.4527,  -8.7016,  -1.8568]],\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.logits.squeeze().shape\n",
    "output.logits.squeeze()[selection, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['take']\n"
     ]
    }
   ],
   "source": [
    "logits_first_mask = output.logits.squeeze()[selection, :][0]\n",
    "predictions = torch.softmax(logits_first_mask, axis = -1)\n",
    "word_id = predictions.argmax()\n",
    "print(tokenizer.convert_ids_to_tokens([word_id ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] you TAKE THE blue pill , the story ends . you wake UP in your BED and believe whatever you want to believe . you take the red pill , you SLEEP in IT , and i TELL you how FAR the rabbit hole goes . [SEP] "
     ]
    }
   ],
   "source": [
    "for i, token_id in enumerate(inputs.input_ids.squeeze()):\n",
    "    if i in selection:\n",
    "        logits_first_mask = output.logits.squeeze()[i]\n",
    "        predictions = torch.softmax(logits_first_mask, axis = -1)\n",
    "        token_id = predictions.argmax()\n",
    "        print(tokenizer.convert_ids_to_tokens([token_id ])[0].upper(), end=' ')\n",
    "    \n",
    "    else:\n",
    "        print(tokenizer.convert_ids_to_tokens([token_id ])[0], end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['you']\n"
     ]
    }
   ],
   "source": [
    "logits_first_mask = output.logits.squeeze()[1, :]\n",
    "predictions = torch.softmax(logits_first_mask, axis = -1)\n",
    "word_id = predictions.argmax()\n",
    "print(tokenizer.convert_ids_to_tokens([word_id ]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
