{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Space Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp.data import load_20news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_20news()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = data.data[:1_000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nlp.data import spacy_lemma_tokenizer\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = ['PUNCT']\n",
    "collection = [spacy_lemma_tokenizer(text=t.replace('\\n', ''), nlp=nlp, filter_tokens=filters) for t in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'be', 'sure', 'some', 'basher', 'of', 'pens', 'fan', 'be', 'pretty', 'confused', 'about', 'the', 'lackof', 'any', 'kind', 'of', 'post', 'about', 'the', 'recent', 'pens', 'massacre', 'of', 'the', 'devils', 'actually', 'i', 'be', ' ', 'bit', 'puzzled', 'too', 'and', 'a', 'bit', 'relieved', 'however', 'i', 'be', 'go', 'to', 'put', 'an', 'endto', 'non', '-', 'pittsburghers', \"'\", 'relief', 'with', 'a', 'bit', 'of', 'praise', 'for', 'the', 'pens', 'man', 'theyare', 'kill', 'those', 'devil', 'bad', 'than', 'i', 'think', 'jagr', 'just', 'show', 'you', 'whyhe', 'be', 'much', 'well', 'than', 'his', 'regular', 'season', 'stat', 'he', 'be', 'also', 'a', 'lotfo', 'fun', 'to', 'watch', 'in', 'the', 'playoff', 'bowman', 'should', 'let', 'jagr', 'have', 'a', 'lot', 'offun', 'in', 'the', 'next', 'couple', 'of', 'game', 'since', 'the', 'pens', 'be', 'go', 'to', 'beat', 'the', 'pulp', 'out', 'of', 'jersey', 'anyway', 'i', 'be', 'very', 'disappointed', 'not', 'to', 'see', 'the', 'islanders', 'lose', 'the', 'finalregular', 'season', 'game', '         ', 'pens', 'rule']\n",
      "============\n",
      "['the', 'blood', 'of', 'the', 'lamb', 'this', 'will', 'be', 'a', 'hard', 'task', 'because', 'most', 'culture', 'use', 'most', 'animalsfor', 'blood', 'sacrifice', 'it', 'have', 'to', 'be', 'something', 'related', 'to', 'our', 'currentpost', 'modernism', 'state', 'hmm', 'what', 'about', 'use', 'computers?cheer', 'kent']\n"
     ]
    }
   ],
   "source": [
    "d_i, d_j = 0, 10\n",
    "print(collection[d_i])\n",
    "print(\"============\")\n",
    "print(collection[d_j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(a, b):\n",
    "    s_a, s_b = set(a), set(b)\n",
    "    return len(s_a.intersection(s_b)) / len(s_a.union(s_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06140350877192982"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard(collection[d_i], collection[d_j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "d1 = spacy_lemma_tokenizer(\"john loves mary\", nlp=nlp, filter_tokens=filters)\n",
    "d2 = spacy_lemma_tokenizer(\"mary loves john\", nlp=nlp, filter_tokens=filters)\n",
    "print(jaccard(d1, d2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the blood of the lamb.\n",
      "\n",
      "This will be a hard task, because most cultures used most animals\n",
      "for blood sacrifices. It has to be something related to our current\n",
      "post-modernism state. Hmm, what about used computers?\n",
      "\n",
      "Cheers,\n",
      "Kent\n"
     ]
    }
   ],
   "source": [
    "example = documents[10]\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blood\n",
      "task\n",
      "cultures\n",
      "animals\n",
      "blood\n",
      "sacrifices\n",
      "state\n",
      "computers\n"
     ]
    }
   ],
   "source": [
    "tokens = [token for token in nlp(example) if token.pos_ in ['NOUN']]\n",
    "for token in tokens:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = defaultdict(lambda: 0)\n",
    "for doc in collection:\n",
    "    for token in doc:\n",
    "        F[token] += 1\n",
    "F = pd.Series(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the     7758\n",
       "be      6180\n",
       "        5479\n",
       "to      3893\n",
       "of      3571\n",
       "a       3196\n",
       "i       3034\n",
       "and     2981\n",
       "in      2236\n",
       "that    2177\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(tokens):\n",
    "    count = defaultdict(lambda: 0)\n",
    "    for token in tokens:\n",
    "        count[token] += 1\n",
    "    return pd.Series(count) / sum(count.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf(collection[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the            0.055556\n",
       "be             0.055556\n",
       "blood          0.055556\n",
       "use            0.055556\n",
       "most           0.055556\n",
       "to             0.055556\n",
       "hmm            0.027778\n",
       "state          0.027778\n",
       "have           0.027778\n",
       "currentpost    0.027778\n",
       "dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df(corpus):\n",
    "    D = defaultdict(lambda: 0)\n",
    "    for doc in corpus:\n",
    "        for token in set(doc):\n",
    "            D[token] += 1\n",
    "    return np.log(len(corpus) / pd.Series(D))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-*-----i          6.907755\n",
       "o.t               6.907755\n",
       "capitalize        6.907755\n",
       "mannamed          6.907755\n",
       "91126             6.907755\n",
       "818               6.907755\n",
       "5457              6.907755\n",
       "babak             6.907755\n",
       "abbreviationof    6.907755\n",
       "caltech           6.907755\n",
       "dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(tokens, idf_data):\n",
    "    count = defaultdict(lambda: 0)\n",
    "    for token in tokens:\n",
    "        count[token] += 1\n",
    "    size = sum(count.values())\n",
    "    tf_idf = {}\n",
    "    for token, tfv in count.items():\n",
    "        tf_idf[token] = (tfv / size) * idf_data[token]\n",
    "    return pd.Series(tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tfidf(collection[20], df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chevrolet    0.075909\n",
       "cab          0.056932\n",
       "truck        0.045507\n",
       "hd           0.043667\n",
       "4x4          0.034146\n",
       "               ...   \n",
       "an           0.003439\n",
       "at           0.003344\n",
       "be           0.003307\n",
       "can          0.003046\n",
       "on           0.002157\n",
       "Length: 201, dtype: float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from string import punctuation \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18846/18846 [00:33<00:00, 562.50it/s]\n"
     ]
    }
   ],
   "source": [
    "targets = data.target\n",
    "docs = data.data \n",
    "sentences = []\n",
    "sentence_targets = []\n",
    "run = list(enumerate(docs))\n",
    "for i, doc in tqdm(run):\n",
    "    for s in sent_tokenize(doc):\n",
    "        s_tokens = [w.lower() for w in word_tokenize(s.replace(\"\\n\", \"\")) if w not in punctuation]\n",
    "        if len(s_tokens) > 10:\n",
    "            sentences.append(s_tokens)\n",
    "            sentence_targets.append(targets[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 10_000\n",
    "sample = sentences[:size]\n",
    "sample_t = sentence_targets[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'am', 'sure', 'some', 'bashers', 'of', 'pens', 'fans', 'are', 'pretty', 'confused', 'about', 'the', 'lackof', 'any', 'kind', 'of', 'posts', 'about', 'the', 'recent', 'pens', 'massacre', 'of', 'the', 'devils']\n",
      "['however', 'i', 'am', 'going', 'to', 'put', 'an', 'endto', 'non-pittsburghers', 'relief', 'with', 'a', 'bit', 'of', 'praise', 'for', 'the', 'pens']\n",
      "['jagr', 'just', 'showed', 'you', 'whyhe', 'is', 'much', 'better', 'than', 'his', 'regular', 'season', 'stats']\n",
      "['he', 'is', 'also', 'a', 'lotfo', 'fun', 'to', 'watch', 'in', 'the', 'playoffs']\n",
      "['bowman', 'should', 'let', 'jagr', 'have', 'a', 'lot', 'offun', 'in', 'the', 'next', 'couple', 'of', 'games', 'since', 'the', 'pens', 'are', 'going', 'to', 'beat', 'the', 'pulp', 'out', 'of', 'jersey', 'anyway']\n",
      "['i', 'was', 'very', 'disappointed', 'not', 'to', 'see', 'the', 'islanders', 'lose', 'the', 'finalregular', 'season', 'game']\n",
      "['my', 'brother', 'is', 'in', 'the', 'market', 'for', 'a', 'high-performance', 'video', 'card', 'that', 'supportsvesa', 'local', 'bus', 'with', '1-2mb', 'ram']\n",
      "['does', 'anyone', 'have', 'suggestions/ideas', 'on', 'diamond', 'stealth', 'pro', 'local', 'bus', 'orchid', 'farenheit', '1280', 'ati', 'graphics', 'ultra', 'pro', 'any', 'other', 'high-performance', 'vlb', 'cardplease', 'post', 'or', 'email']\n",
      "['the', 'area', 'will', 'be', '``', 'greater', \"''\", 'after', 'some', 'years', 'like', 'your', '``', 'holocaust', \"''\", 'numbers', '......', \"is't\", 'july', 'in', 'usa', 'now']\n",
      "['nothing', 'of', 'the', 'mentioned', 'is', 'true', 'but', 'let', 'say', 'it', \"'s\", 'true']\n"
     ]
    }
   ],
   "source": [
    "for s in sample[:10]:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 rec.sport.hockey\n",
      "10 rec.sport.hockey\n",
      "10 rec.sport.hockey\n",
      "10 rec.sport.hockey\n",
      "10 rec.sport.hockey\n",
      "10 rec.sport.hockey\n",
      "3 comp.sys.ibm.pc.hardware\n",
      "3 comp.sys.ibm.pc.hardware\n",
      "17 talk.politics.mideast\n",
      "17 talk.politics.mideast\n"
     ]
    }
   ],
   "source": [
    "for target in sample_t[:10]:\n",
    "    print(target, data.target_names[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfIdf by sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(lowercase=False, min_df=5, token_pattern=None,\n",
       "                tokenizer=&lt;function &lt;lambda&gt; at 0x15ccf45e0&gt;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(lowercase=False, min_df=5, token_pattern=None,\n",
       "                tokenizer=&lt;function &lt;lambda&gt; at 0x15ccf45e0&gt;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(lowercase=False, min_df=5, token_pattern=None,\n",
       "                tokenizer=<function <lambda> at 0x15ccf45e0>)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = lambda x: x\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenizer, token_pattern=None, lowercase=False, min_df=5)\n",
    "tfidf.fit(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tfidf.transform(sample).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400\n",
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "features = list(tfidf.get_feature_names_out())\n",
    "cat_i = features.index('cat')\n",
    "print(cat_i)\n",
    "print(m[:, cat_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = tfidf.transform(['this room is full of blood because of a sacrifice'.split()]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = cosine_similarity(q, m)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking = [(i, w) for i, w in sorted(enumerate(sigma), key=lambda x: -x[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blood transfusions wereimpossible because they had no facilities to test blood types 0.36096948047834637\n",
      "mark 's account in 12:28-34 casts the answerin a far more positive light as so the `` scribe '' in this version says '' far more important than any holocaust i need to point out that this wordoriginates in the context of animal sacrifice forget the nazis for this or sacrifice '' 0.28513030430152314\n",
      "a full discussion of this procedure is outside the scope of this faq 0.2588053748114578\n",
      "this faq is so full of error that imust respond to it 0.24197728055639167\n",
      "i could feel the temptation and just angrily ordered the kidto his/her room and went to my room myself 0.23675523501769472\n",
      "this will be a hard task because most cultures used most animalsfor blood sacrifices 0.2296314548893739\n",
      "here is your chance to have a full unix system at a small cost i have a full set of unix system for the at t 6300+ for sale 0.20890602844500752\n",
      "the thrust of the passagein its context is to liken the one time incarnation and sacrifice of christ for all mankind to the individual experience of the human being after death 0.20694768678436284\n",
      "in a room next to it we glimpsed the body of a woman shot in thehead 0.19969617373759824\n",
      "is the affected hgastill limited or is it now capable of full range of motion 0.19597066159166404\n"
     ]
    }
   ],
   "source": [
    "for d_id, score in ranking[:10]:\n",
    "    print(\" \".join(sample[d_id]), score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
