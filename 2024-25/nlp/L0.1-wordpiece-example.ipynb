{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlp.wordpiece as wp\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from string import punctuation\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Years ago, the fearsome Pirate King, Gol D. Roger was executed leaving a huge pile of treasure and the famous \"One Piece\" behind. \n",
    "Whoever claims the \"One Piece\" will be named the new King of the Pirates.\n",
    "Monkey D. Luffy, a boy who consumed a \"Devil Fruit,\" decides to follow in the footsteps of his idol, the pirate Shanks, and find the One Piece. \n",
    "It helps, of course, that his body has the properties of rubber and that he's surrounded by a bevy of skilled fighters and thieves to help him along the way.\n",
    "Luffy will do anything to get the One Piece and become King of the Pirates!\"\"\"\n",
    "print(len(text.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt = wp.WordPieceTokenizer(text=text, maximum_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t   #h    15\n",
      "#h  #e    12\n",
      "#n  #d     8\n",
      "P   #i     7\n",
      "#i  #n     7\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "example = wt.score_pairs(normalize=False)\n",
    "print(example.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 214/500 [00:00<00:00, 2438.50it/s]\n"
     ]
    }
   ],
   "source": [
    "wt.train(normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Years | ago, | the | fearsome | Pirate | King, | Gol | D. | Roger | was | executed | leaving | a | huge | pile | of | treasure | and | the | famous | \"One | Piece\" | behind. | Whoever | claims | the | \"One | Piece\" | will | be | named | the | new | King | of | the | Pirates. | Monkey | D. | Luffy, | a | boy | who | consumed | a | \"Devil | Fruit,\" | decides | to | follow | in | the | footsteps | of | his | idol, | the | pirate | Shanks, | and | find | the | One | Piece. | It | helps, | of | course, | that | his | body | has | the | properties | of | rubber | and | that | he's | surrounded | by | a | bevy | of | skilled | fighters | and | thieves | to | help | him | along | the | way. | Luffy | will | do | anything | to | get | the | One | Piece | and | become | King | of | the | Pirates!\n"
     ]
    }
   ],
   "source": [
    "tokenized = []\n",
    "for tokens in wt.corpus:\n",
    "    tokenized.extend(list(tokens))\n",
    "print(\" | \".join(tokenized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Y          1\n",
       "Luffy,     1\n",
       "boy        1\n",
       "who        1\n",
       "con        1\n",
       "          ..\n",
       "#s        22\n",
       "#n        23\n",
       "#o        25\n",
       "#i        29\n",
       "#e        67\n",
       "Length: 275, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = wt.fancy_vocabulary\n",
    "V.sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pirate', '#s', '[UNK]', 'to', 'a', '#s', '#s', '#a', '#u', '#l', '#t', 's', '#h', '#i', '#p', '#s', 'o', '#n', 'the', 's', '#ea']\n"
     ]
    }
   ],
   "source": [
    "test = \"pirates use to assault ships on the sea\"\n",
    "print(wt.tokenize_text(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['King', 'of', 'the', 'pirate', '#s']\n"
     ]
    }
   ],
   "source": [
    "test = \"King of the pirates\"\n",
    "print(wt.tokenize_text(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterazione 0: c #o #n #s #u #m #e #d a\n",
      "Iterazione 16: c #o #n #s #u #m #ed a\n",
      "Iterazione 34: c #o #n #s #u #med a\n",
      "Iterazione 35: c #on #s #u #med a\n",
      "Iterazione 58: c #on #su #med a\n",
      "Iterazione 116: con #su #med a\n",
      "Iterazione 117: consu #med a\n",
      "Iterazione 118: consumed a\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Years ago, the fearsome Pirate King, Gol D. Roger was executed leaving a huge pile of treasure and the famous \"One Piece\" behind. \n",
    "Whoever claims the \"One Piece\" will be named the new King of the Pirates.\n",
    "Monkey D. Luffy, a boy who consumed a \"Devil Fruit,\" decides to follow in the footsteps of his idol, the pirate Shanks, and find the One Piece. \n",
    "It helps, of course, that his body has the properties of rubber and that he's surrounded by a bevy of skilled fighters and thieves to help him along the way.\n",
    "Luffy will do anything to get the One Piece and become King of the Pirates!\n",
    "\"\"\"\n",
    "example = \"consumed a\"\n",
    "current = \"\"\n",
    "normalize = False \n",
    "wt = wp.WordPieceTokenizer(text=text, maximum_size=500)\n",
    "iterations = list(range(wt.max_vocabulary_size))\n",
    "for i in iterations:\n",
    "    check = wt.update(normalize=normalize)\n",
    "    tokens = wt.tokenize_text(example)\n",
    "    if tokens != current:\n",
    "        print(\"Iterazione {}: {}\".format(i, \" \".join(tokens)))\n",
    "        current = tokens\n",
    "    if not check:\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "275"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wt.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c 3\n",
      "cl 1\n",
      "cla 1\n",
      "clai 1\n",
      "claim 1\n",
      "claims 1\n",
      "con 1\n",
      "consu 1\n",
      "consumed 1\n",
      "cou 1\n",
      "cours 1\n",
      "course 1\n",
      "course, 1\n"
     ]
    }
   ],
   "source": [
    "for w, s in wt.fancy_vocabulary.items():\n",
    "    if w.startswith('c'):\n",
    "        print(w, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testo originale: mix mixing mixed mixes mixer mixade\n",
      "Token: ['mix', 'mixing', 'mixed', 'mixes', 'mixer', 'mix', '##ade']\n",
      "Token IDs: [4666, 6809, 3816, 21109, 23228, 4666, 9648]\n"
     ]
    }
   ],
   "source": [
    "example = \"mix mixing mixed mixes mixer mixade\"\n",
    "\n",
    "tokens = tokenizer.tokenize(example)\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "print(\"Testo originale:\", example)\n",
    "print(\"Token:\", tokens)\n",
    "print(\"Token IDs:\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
